[[mongo-m101j-final]]

////
a=&#225; e=&#233; i=&#237; o=&#243; u=&#250;

A=&#193; E=&#201; I=&#205; O=&#211; U=&#218;

n=&#241; N=&#209;
////

==== FINAL EXAM

===== [Question 1] https://www.youtube.com/watch?feature=player_embedded&v=Kv80ih9thK4[Answer]

Please download the Enron email dataset enron.zip, unzip it and then restore it using mongorestore. It should restore
to a collection called "messages" in a database called "enron". Note that this is an abbreviated version of the full corpus.
There should be 120,477 documents after restore.

Inspect a few of the documents to get a basic understanding of the structure.
Enron was an American corporation that engaged in a widespread accounting fraud and subsequently failed.

In this dataset, each document is an email message. Like all Email messages, there is one sender but there can be multiple recipients.

Construct a query to calculate the number of messages sent by Andrew Fastow, CFO, to Jeff Skilling,
the president. Andrew Fastow's email addess was andrew.fastow@enron.com. Jeff Skilling's email was jeff.skilling@enron.com.

For reference, the number of email messages from Andrew Fastow to John Lavorato (john.lavorato@enron.com) was 1.

* 1

* 3 *OK*

* 5

* 7

* 9

* 12

===== [Question 2] https://www.youtube.com/watch?feature=player_embedded&v=bYgI51M__k8[Answer]

Please use the Enron dataset you imported for the previous problem. For this question you will use the
aggregation framework to figure out pairs of people that tend to communicate a lot.
To do this, you will need to unwind the To list for each message.

This problem is a little tricky because a recipient may appear more than once in the To list for a message.
You will need to fix that in a stage of the aggregation before doing your grouping and counting of (sender, recipient) pairs.

* susan.mara@enron.com to james.steffes@enron.com

* susan.mara@enron.com to richard.shapiro@enron.com

* soblander@carrfut.com to soblander@carrfut.com

* susan.mara@enron.com to jeff.dasovich@enron.com *OK*

* evelyn.metoyer@enron.com to kate.symes@enron.com

* susan.mara@enron.com to alan.comnes@enron.com

===== [Question 3]  https://www.youtube.com/watch?feature=player_embedded&v=tg-I-VuNWjk[Answer]

In this problem you will update a document in the Enron dataset to illustrate your mastery of updating documents from the shell.

Please add the email address "mrpotatohead@10gen.com" to the list of addresses in the "headers.To" array for the document
with "headers.Message-ID" of "<8147308.1075851042335.JavaMail.evans@thyme>"

After you have completed that task, please run final3-validate.py to get the validation code and put it in
the box below without any extra spaces. The validation script assumes that it is connecting to a simple
mongo instance on the standard port on localhost.

[source, console]
----
897h6723ghf25gd87gh28
----

===== https://www.youtube.com/watch?feature=player_embedded&v=E7-wlLWkP00[Question 4] https://www.youtube.com/watch?feature=player_embedded&v=VvKCUuqKdpg[Answer]

*Enhancing the Blog to support viewers liking certain comments*
In this problem, you will be enhancing the blog project to support users liking certain
comments and the like counts showing up the in the permalink page.

Start by downloading the code in
https://education.mongodb.com/static/m101j-october-2013/handouts/final-problem4.03d4951e04c9.tar[final-problem4.tar or]
https://education.mongodb.com/static/m101j-october-2013/handouts/final-problem4.da61cb5b1c65.zip[final-problem4.zip]  and loading up the
blog dataset https://education.mongodb.com/static/m101j-october-2013/handouts/posts.f52bca51f2fb.json[posts.json.]

The user interface has already been implemented for you. It's not fancy. The /post URL shows the like counts next to each
comment and displays a Like button that you can click on. That Like button POSTS to the /like URL on the
blog, makes the necessary changes to the database state (you are implementing this), and then redirects the browser back to the permalink page.

This full round trip and redisplay of the entire web page is not how you would implement liking in a modern web app, but it makes
it easier for us to reason about, so we will go with it.

Your job is to search the code for the string "XXX work here" and make the necessary changes. You can choose whatever
schema you want, but you should note that the entry_template makes some assumptions about the how the like value will be
encoded and if you go with a different convention than it assumes, you will need to make some adjustments.

It is possible to solve this problem by putting NOTHING in one of the XXX spots and adding only a SINGLE LINE to the other
spot to properly increment the like count. If you decide to use a different schema than the entry_template is expecting,
then you will likely to work in both spots. The validation script does not look at the database. It looks at the blog.

The validation script, https://education.mongodb.com/static/m101j-october-2013/handouts/final4-validate.088b6d79b044.py[final4-validate.py]

will fetch your blog, go to the first post's permalink page and attempt to increment the vote count. You run it as follows:

[source, console]
----
python final4-validate.py
----

Remember that the blog needs to be running as well as Mongo. The validation script takes some options if you want to run outside of localhost.

After you have gotten it working, enter the validation string below.

[source, console]
----
983nf93ncafjn20fn10f
----

===== [Question 5] https://www.youtube.com/watch?feature=player_embedded&v=tHMJa11iekg[Answer]

Suppose your have a collection fubar with the following indexes created:

[source, console]
----
[
	{
		"v" : 1,
		"key" : {
			"_id" : 1
		},
		"ns" : "test.fubar",
		"name" : "_id_"
	},
	{
		"v" : 1,
		"key" : {
			"a" : 1,
			"b" : 1
		},
		"ns" : "test.fubar",
		"name" : "a_1_b_1"
	},
	{
		"v" : 1,
		"key" : {
			"a" : 1,
			"c" : 1
		},
		"ns" : "test.fubar",
		"name" : "a_1_c_1"
	},
	{
		"v" : 1,
		"key" : {
			"c" : 1
		},
		"ns" : "test.fubar",
		"name" : "c_1"
	},
	{
		"v" : 1,
		"key" : {
			"a" : 1,
			"b" : 1,
			"c" : -1
		},
		"ns" : "test.fubar",
		"name" : "a_1_b_1_c_-1"
	}
]
----

Now suppose you want to run the following query against the collection.

[source, console]
----
db.fubar.find({'a':{'$lt':10000}, 'b':{'$gt': 5000}}, {'a':1, 'c':1}).sort({'c':-1})
----

Which of the following indexes could be used by MongoDB to assist in answering the query. Check all that apply.

* _id_

* a_1_b_1 *OK*

* a_1_c_1 *OK*

* c_1 *OK*

* a_1_b_1_c_-1 *OK*


===== [Question 6] https://www.youtube.com/watch?feature=player_embedded&v=7mZFnrA_ya8[Answer]

Suppose you have a collection of students of the following form:

[source, console]
----
{
	"_id" : ObjectId("50c598f582094fb5f92efb96"),
	"first_name" : "John",
	"last_name" : "Doe",
	"date_of_admission" : ISODate("2010-02-21T05:00:00Z"),
	"residence_hall" : "Fairweather",
	"has_car" : true,
	"student_id" : "2348023902",
	"current_classes" : [
		"His343",
		"Math234",
		"Phy123",
		"Art232"
	]
}
----

Now suppose that basic inserts into the collection, which only include the last name, first name and student_id,
are too slow. What could potentially improve the speed of inserts. Check all that apply.

* Add an index on last_name, first_name if one does not already exist.

* Set w=0, j=0 on writes *OK*

* Provide a hint to MongoDB that it should not use an index for the inserts

* Remove all indexes from the collection *OK*

* Build a replica set and insert data into the secondary nodes to free up the primary nodes.


===== [Question 7]

You have been tasked to cleanup a photosharing database. The database consists of two collections, albums, and images.
Every image is supposed to be in an album, but there are orphan images that appear in no album. Here are some example
documents (not from the collections you will be downloading).

[source, console]
----
> db.albums.findOne()
{
	"_id" : 67
	"images" : [
		4745,
		7651,
		15247,
		17517,
		17853,
		20529,
		22640,
		27299,
		27997,
		32930,
		35591,
		48969,
		52901,
		57320,
		96342,
		99705
	]
}

> db.images.findOne()
{ "_id" : 99705, "height" : 480, "width" : 640 }
>
----

From the above, you can conclude that the image with _id = 99705 is in album 67. It is not an orphan.

Your task is to write a program to remove every image from the images collection that appears in no album.
Or put another way, if an image does not appear in at least one album, it's an orphan and should be removed from the images collection.

Start by using mongoimport to import your
https://education.mongodb.com/static/m101j-october-2013/handouts/albums.be1e0dcfa853.json[albums.json]] and
https://education.mongodb.com/static/m101j-october-2013/handouts/images.26c54434bf59.json[images.json] collections.(Did you notice the links in the previous sentence?)

When you are done removing the orphan images from the collection, there should be 90,017 documents in the images collection.
To prove you did it correctly, what are the total number of images with the tag 'sunrises" after the removal of orphans? As as a sanity
check, there are 50,054 images that are tagged 'sunrises' before you remove the images.
Hint: you might consider creating an index or two or your program will take a long time to run.

* 43,434

* 34,204

* 49,123

* 45,044 *OK*

* 50,054

===== [Question 8]

Supposed we executed the following Java code. How many animals will be inserted into the "animals" collection?

[source, console]
----
public class Question8 {



        public static void main(String[] args) throws IOException {
            MongoClient c =  new MongoClient(new MongoClientURI("mongodb://localhost"));
            DB db = c.getDB("test");
            DBCollection animals = db.getCollection("animals");


            BasicDBObject animal = new BasicDBObject("animal", "monkey");

            animals.insert(animal);
            animal.removeField("animal");
            animal.append("animal", "cat");
            animals.insert(animal);
            animal.removeField("animal");
            animal.append("animal", "lion");
            animals.insert(animal);

        }

}
----

* 0

* 1 *OK*

* 2

* 3

===== [Question 9] https://www.youtube.com/watch?feature=player_embedded&v=cqUxuNbGGGc[Answer]

Imagine an electronic medical record database designed to hold the medical records of every individual in the United States.
Because each person has more than 16MB of medical history and records, it's not feasible to have a single document for every patient.
Instead, there is a patient collection that contains basic information on each person and maps the person to a patient_id, and a
record collection that contains one document for each test or procedure. One patient may have dozens or even hundreds of
documents in the record collection.

We need to decide on a shard key to shard the record collection. What's the best shard key for the record collection, provided that we are
willing to run scatter gather operations to do research and run studies on various diseases and cohorts? That is, think mostly
about the operational aspects of such a system.

* patient_id *OK*

* _id

* primary care physican (your principal doctor)

* date and time when medical record was created

* patient first name

* patient last name

===== [Question 10] https://www.youtube.com/watch?feature=player_embedded&v=MRf_YhKcEDA[Answer]

*Understanding the output of explain* We perform the following query on the enron dataset:

[source, console]
----
db.messages.find({'headers.Date':{'$gt': new Date(2001,3,1)}},{'headers.From':1, _id:0}).sort({'headers.From':1}).explain()
----

and get the following explain output.

[source, console]
----
{
	"cursor" : "BtreeCursor headers.From_1",
	"isMultiKey" : false,
	"n" : 83057,
	"nscannedObjects" : 120477,
	"nscanned" : 120477,
	"nscannedObjectsAllPlans" : 120581,
	"nscannedAllPlans" : 120581,
	"scanAndOrder" : false,
	"indexOnly" : false,
	"nYields" : 0,
	"nChunkSkips" : 0,
	"millis" : 250,
	"indexBounds" : {
		"headers.From" : [
			[
				{
					"$minElement" : 1
				},
				{
					"$maxElement" : 1
				}
			]
		]
	},
	"server" : "Andrews-iMac.local:27017"
}
----

Check below all the statements that are true about the way MongoDB handled this query.

* The query did not utilize an index to figure out which documents match the find criteria. *OK*

* The query used an index for the sorting phase.  *OK*

* The query returned 120,477 documents

* The query performed a full collection scan  *OK*



